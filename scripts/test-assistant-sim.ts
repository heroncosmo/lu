// ============================================================================
// TESTE DE PERFORMANCE DO ASSISTENTE - SIMULAÃ‡ÃƒO COMPLETA
// ============================================================================
// Este script simula EXATAMENTE a chamada do Assistente de Prompts
// com um prompt de 21k caracteres e testa diferentes configuraÃ§Ãµes.
// ============================================================================

// Gerar prompt de 21k caracteres (simulando o do Leandro)
function generateLargePrompt(): string {
  const instruction = `VocÃª Ã© um especialista em estratÃ©gia de vendas, relacionamento com clientes e psicologia comportamental. 
Seu objetivo Ã© ajudar vendedores a aumentar significativamente suas conversÃµes atravÃ©s de tÃ©cnicas de persuasÃ£o Ã©tica.

CONHECIMENTOS PROFUNDOS:
- Psicologia de vendas: AIDA (AtenÃ§Ã£o, Interesse, Desejo, AÃ§Ã£o), SPIN selling, tÃ©cnicas de fechamento provadas
- Rapport: Espelhamento neurolinguÃ­stico, sincronizaÃ§Ã£o corporal, linguagem hipnÃ³tica
- NegociaÃ§Ã£o: ObjeÃ§Ã£o handling estratÃ©gico, win-win negotiation, BATNA strategy
- ComunicaÃ§Ã£o: Linguagem de padrÃµes, storytelling persuasivo, framing cognitivo
- Ã‰tica: Sempre respeitar o cliente, transparÃªncia completa, honestidade radical

INSTRUÃ‡Ã•ES DETALHADAS:
1. Analise profundamente o contexto da venda e do perfil do cliente
2. Identifique possÃ­veis objeÃ§Ãµes e prepare antÃ­dotos com base em psicologia
3. Sugira uma sequÃªncia de passos com linguagem especÃ­fica e testada
4. Mantenha total Ã©tica e respeito ao cliente em toda interaÃ§Ã£o
5. Considere o timing perfeito e o canal de comunicaÃ§Ã£o mais efetivo
6. DÃª exemplos prÃ¡ticos de fala exata que o vendedor pode usar
7. Sempre explique o 'por quÃª' das suas sugestÃµes - educaÃ§Ã£o, nÃ£o manipulaÃ§Ã£o

EXEMPLOS DE PADRÃ•ES DE LINGUAGEM:
- "Eu entendo que vocÃª esteja preocupado com [objeÃ§Ã£o]..."
- "O que torna este produto diferente Ã© [benefÃ­cio]..."
- "Posso fazer uma pergunta?"
- "Imagine por um momento que vocÃª jÃ¡ resolveu..."

CASOS DE USO:
1. Vendas B2B: ROI, integraÃ§Ã£o, suporte
2. ServiÃ§os: Outcomes, credibilidade
3. Consultivas: DiagnÃ³stico, soluÃ§Ã£o
4. Transacionais: ConveniÃªncia, preÃ§o`;

  let prompt = instruction;
  while (prompt.length < 21000) {
    prompt += "\n\n---\n" + instruction;
  }
  return prompt.substring(0, 21679);
}

// Construir system prompt IGUAL ao do cÃ³digo real
function buildSystemPrompt(agentInstructions: string): string {
  return `VocÃª Ã© um especialista em criar prompts para agentes de IA de vendas e atendimento.
Seu objetivo Ã© ajudar a melhorar o prompt do agente "Leandro aÃ­".

PROMPT ATUAL DO AGENTE:
"""
${agentInstructions}
"""

REGRAS:
1. Quando o usuÃ¡rio pedir melhorias, sugira alteraÃ§Ãµes especÃ­ficas e explique o porquÃª
2. Quando vocÃª propor um novo prompt, formate-o EXATAMENTE assim:
   [NOVO_PROMPT_INICIO]
   <o prompt completo aqui>
   [NOVO_PROMPT_FIM]
3. Seja especÃ­fico e prÃ¡tico nas sugestÃµes
4. Mantenha o tom profissional do agente
5. Sugira melhorias baseadas em boas prÃ¡ticas de vendas e persuasÃ£o
6. Pergunte sobre o contexto e objetivos antes de fazer grandes mudanÃ§as

Responda em portuguÃªs brasileiro.`;
}

// ConfiguraÃ§Ãµes para testar
interface TestConfig {
  name: string;
  model: string;
  maxTokens: number;
  reasoningEffort?: string;
  temperature: number;
  role: "developer" | "system";
}

const CONFIGS: TestConfig[] = [
  // Config atual do cÃ³digo
  {
    name: "ATUAL (gpt-5.1 + reasoning:none)",
    model: "gpt-5.1",
    maxTokens: 4000,
    reasoningEffort: "none",
    temperature: 0.7,
    role: "developer",
  },
  // gpt-4.1 (nÃ£o-reasoning, pode ser mais rÃ¡pido)
  {
    name: "gpt-4.1 (nÃ£o-reasoning)",
    model: "gpt-4.1",
    maxTokens: 4000,
    temperature: 0.7,
    role: "system",
  },
  // gpt-4.1-mini (mais rÃ¡pido)
  {
    name: "gpt-4.1-mini (econÃ´mico)",
    model: "gpt-4.1-mini",
    maxTokens: 4000,
    temperature: 0.7,
    role: "system",
  },
  // gpt-4o (modelo padrÃ£o)
  {
    name: "gpt-4o (padrÃ£o)",
    model: "gpt-4o",
    maxTokens: 4000,
    temperature: 0.7,
    role: "system",
  },
  // gpt-4o-mini (mais econÃ´mico)
  {
    name: "gpt-4o-mini (mais econÃ´mico)",
    model: "gpt-4o-mini",
    maxTokens: 4000,
    temperature: 0.7,
    role: "system",
  },
];

interface TestResult {
  config: string;
  time: number;
  tokens: number;
  responseLength: number;
  success: boolean;
  error?: string;
}

async function testConfig(
  config: TestConfig,
  systemPrompt: string,
  userMessage: string,
  apiKey: string
): Promise<TestResult> {
  const startTime = Date.now();

  try {
    const body: any = {
      model: config.model,
      messages: [
        { role: config.role, content: systemPrompt },
        { role: "user", content: userMessage },
      ],
      temperature: config.temperature,
    };

    // GPT-5.1 usa max_completion_tokens e reasoning_effort
    if (config.model.includes("5.1") || config.model.includes("o1") || config.model.includes("o3")) {
      body.max_completion_tokens = config.maxTokens;
      if (config.reasoningEffort) {
        body.reasoning_effort = config.reasoningEffort;
      }
    } else {
      body.max_tokens = config.maxTokens;
    }

    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${apiKey}`,
      },
      body: JSON.stringify(body),
    });

    const endTime = Date.now();
    const elapsed = endTime - startTime;

    if (!response.ok) {
      const errorData = await response.json();
      return {
        config: config.name,
        time: elapsed,
        tokens: 0,
        responseLength: 0,
        success: false,
        error: errorData.error?.message || "Erro desconhecido",
      };
    }

    const data = await response.json();
    const responseContent = data.choices[0].message.content || "";

    return {
      config: config.name,
      time: elapsed,
      tokens: data.usage?.completion_tokens || 0,
      responseLength: responseContent.length,
      success: true,
    };
  } catch (error: any) {
    return {
      config: config.name,
      time: Date.now() - startTime,
      tokens: 0,
      responseLength: 0,
      success: false,
      error: error.message,
    };
  }
}

async function main() {
  // Verificar chave API
  const apiKey = process.env.OPENAI_API_KEY;

  if (!apiKey) {
    console.log("\nâŒ OPENAI_API_KEY nÃ£o definida!\n");
    console.log("Execute assim:");
    console.log("   $env:OPENAI_API_KEY='sk-proj-...'; npx tsx scripts/test-assistant-sim.ts\n");
    process.exit(1);
  }

  console.log("\n");
  console.log("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
  console.log("â•‘  TESTE DE PERFORMANCE DO ASSISTENTE DE PROMPTS                 â•‘");
  console.log("â•‘  Prompt simulado: 21.679 caracteres (igual ao do Leandro)      â•‘");
  console.log("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

  // Gerar prompt de 21k
  const agentInstructions = generateLargePrompt();
  const systemPrompt = buildSystemPrompt(agentInstructions);
  const userMessage = "fale mais persuasivo e inteligente";

  console.log(`ğŸ“ InstruÃ§Ãµes do agente: ${agentInstructions.length.toLocaleString()} caracteres`);
  console.log(`ğŸ“‹ System prompt total: ${systemPrompt.length.toLocaleString()} caracteres`);
  console.log(`ğŸ’¬ Mensagem do usuÃ¡rio: "${userMessage}"\n`);

  console.log("â•".repeat(70));
  console.log("Testando cada modelo (pode demorar 2-3 min)...\n");

  const results: TestResult[] = [];

  for (const config of CONFIGS) {
    process.stdout.write(`ğŸ§ª ${config.name.padEnd(35)}... `);
    const result = await testConfig(config, systemPrompt, userMessage, apiKey);
    results.push(result);

    if (result.success) {
      console.log(
        `âœ… ${(result.time / 1000).toFixed(2)}s | ${result.tokens} tokens`
      );
    } else {
      console.log(`âŒ ${result.error?.substring(0, 40)}...`);
    }

    // Esperar 1s entre testes
    await new Promise((r) => setTimeout(r, 1000));
  }

  // Ordenar por tempo
  const successResults = results.filter((r) => r.success);
  successResults.sort((a, b) => a.time - b.time);

  console.log("\n" + "â•".repeat(70));
  console.log("\nğŸ“Š RANKING (mais rÃ¡pido primeiro):\n");

  successResults.forEach((r, i) => {
    const medal = i === 0 ? "ğŸ¥‡" : i === 1 ? "ğŸ¥ˆ" : i === 2 ? "ğŸ¥‰" : "  ";
    const timeStr = `${(r.time / 1000).toFixed(2)}s`.padEnd(8);
    const tokensStr = `${r.tokens} tokens`.padEnd(12);
    console.log(`${medal} ${timeStr} | ${tokensStr} | ${r.config}`);
  });

  if (successResults.length > 0) {
    const fastest = successResults[0];
    const current = results.find((r) => r.config.includes("ATUAL"));

    console.log("\n" + "â•".repeat(70));
    console.log("\nğŸ¯ ANÃLISE:\n");

    if (current && current.success) {
      console.log(`   ConfiguraÃ§Ã£o ATUAL (gpt-5.1): ${(current.time / 1000).toFixed(2)}s`);
      console.log(`   ConfiguraÃ§Ã£o mais rÃ¡pida: ${(fastest.time / 1000).toFixed(2)}s`);

      if (fastest.config !== current.config) {
        const speedup = (((current.time - fastest.time) / current.time) * 100).toFixed(0);
        console.log(`\n   âš¡ Potencial de melhoria: ${speedup}% mais rÃ¡pido!`);
        console.log(`   ğŸ‘‰ Recomendo: ${fastest.config}`);
      } else {
        console.log(`\n   âœ… A configuraÃ§Ã£o atual jÃ¡ Ã© a mais rÃ¡pida!`);
      }
    }
  }

  console.log("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
  console.log("â•‘  TESTE COMPLETO                                                â•‘");
  console.log("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
}

main().catch(console.error);
