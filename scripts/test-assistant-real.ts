// ============================================================================
// TESTE REALISTA DO ASSISTENTE DE PROMPTS - BUSCA CHAVE DO SUPABASE
// ============================================================================

import { createClient } from "@supabase/supabase-js";

const supabaseUrl = "https://bnfpcuzjvycudccycqqt.supabase.co";
const supabaseKey = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImJuZnBjdXpqdnljdWRjY3ljcXF0Iiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc2MjM1MzM4OSwiZXhwIjoyMDc3OTI5Mzg5fQ.EIfKg_UwNVTtSiXa5L6eVYfl6_zlJU1m7EGP0jXa0us";

const supabase = createClient(supabaseUrl, supabaseKey);

// Construir system prompt IGUAL ao do cÃ³digo real
function buildSystemPrompt(agentName: string, agentInstructions: string): string {
  return `VocÃª Ã© um especialista em criar prompts para agentes de IA de vendas e atendimento.
Seu objetivo Ã© ajudar a melhorar o prompt do agente "${agentName}".

PROMPT ATUAL DO AGENTE:
"""
${agentInstructions}
"""

REGRAS:
1. Quando o usuÃ¡rio pedir melhorias, sugira alteraÃ§Ãµes especÃ­ficas e explique o porquÃª
2. Quando vocÃª propor um novo prompt, formate-o EXATAMENTE assim:
   [NOVO_PROMPT_INICIO]
   <o prompt completo aqui>
   [NOVO_PROMPT_FIM]
3. Seja especÃ­fico e prÃ¡tico nas sugestÃµes
4. Mantenha o tom profissional do agente
5. Sugira melhorias baseadas em boas prÃ¡ticas de vendas e persuasÃ£o
6. Pergunte sobre o contexto e objetivos antes de fazer grandes mudanÃ§as

Responda em portuguÃªs brasileiro.`;
}

// Mensagem do usuÃ¡rio (tÃ­pica do Assistente de Prompts)
const USER_MESSAGE = "fale mais persuasivo e inteligente";

// ConfiguraÃ§Ãµes para testar
interface TestConfig {
  name: string;
  model: string;
  maxTokens: number;
  reasoningEffort?: string;
  temperature: number;
  role: "developer" | "system";
}

const CONFIGS: TestConfig[] = [
  // Config atual do cÃ³digo
  {
    name: "ATUAL (gpt-5.1 + 9k tokens)",
    model: "gpt-5.1",
    maxTokens: 9227,
    reasoningEffort: "none",
    temperature: 0.7,
    role: "developer",
  },
  // Teste com menos tokens (resposta mais curta)
  {
    name: "gpt-5.1 + 4k tokens (menos)",
    model: "gpt-5.1",
    maxTokens: 4000,
    reasoningEffort: "none",
    temperature: 0.7,
    role: "developer",
  },
  // Teste com gpt-4.1 (nÃ£o-reasoning, mais rÃ¡pido)
  {
    name: "gpt-4.1 + 4k tokens",
    model: "gpt-4.1",
    maxTokens: 4000,
    temperature: 0.7,
    role: "system",
  },
  // Teste com gpt-4.1-mini (mais rÃ¡pido ainda)
  {
    name: "gpt-4.1-mini + 4k tokens",
    model: "gpt-4.1-mini",
    maxTokens: 4000,
    temperature: 0.7,
    role: "system",
  },
  // Teste com gpt-4o (modelo padrÃ£o, bom equilÃ­brio)
  {
    name: "gpt-4o + 4k tokens",
    model: "gpt-4o",
    maxTokens: 4000,
    temperature: 0.7,
    role: "system",
  },
];

interface TestResult {
  config: string;
  time: number;
  tokens: number;
  responseLength: number;
  success: boolean;
  error?: string;
}

async function testConfig(
  config: TestConfig,
  systemPrompt: string,
  userMessage: string,
  apiKey: string
): Promise<TestResult> {
  const startTime = Date.now();

  try {
    const body: any = {
      model: config.model,
      messages: [
        { role: config.role, content: systemPrompt },
        { role: "user", content: userMessage },
      ],
      temperature: config.temperature,
    };

    // GPT-5.1 usa max_completion_tokens e reasoning_effort
    if (
      config.model.includes("5.1") ||
      config.model.includes("o1") ||
      config.model.includes("o3")
    ) {
      body.max_completion_tokens = config.maxTokens;
      if (config.reasoningEffort) {
        body.reasoning_effort = config.reasoningEffort;
      }
    } else {
      // Outros modelos usam max_tokens
      body.max_tokens = config.maxTokens;
    }

    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${apiKey}`,
      },
      body: JSON.stringify(body),
    });

    const endTime = Date.now();
    const elapsed = endTime - startTime;

    if (!response.ok) {
      const errorData = await response.json();
      return {
        config: config.name,
        time: elapsed,
        tokens: 0,
        responseLength: 0,
        success: false,
        error: errorData.error?.message || "Erro desconhecido",
      };
    }

    const data = await response.json();
    const responseContent = data.choices[0].message.content || "";

    return {
      config: config.name,
      time: elapsed,
      tokens: data.usage?.completion_tokens || 0,
      responseLength: responseContent.length,
      success: true,
    };
  } catch (error: any) {
    return {
      config: config.name,
      time: Date.now() - startTime,
      tokens: 0,
      responseLength: 0,
      success: false,
      error: error.message,
    };
  }
}

async function main() {
  console.log("\n");
  console.log("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
  console.log("â•‘  TESTE DE PERFORMANCE DO ASSISTENTE DE PROMPTS                 â•‘");
  console.log("â•‘  Usando dados REAIS do Supabase (agente do Leandro)            â•‘");
  console.log("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

  // Buscar agente do Supabase
  console.log("ğŸ“¥ Buscando agente do Supabase...");
  
  const { data: agents, error } = await supabase
    .from("agents")
    .select("*")
    .limit(5);

  if (error) {
    console.error("âŒ Erro ao buscar agentes:", error.message);
    process.exit(1);
  }

  if (!agents || agents.length === 0) {
    console.error("âŒ Nenhum agente encontrado!");
    process.exit(1);
  }

  // Mostrar agentes disponÃ­veis
  console.log("\nğŸ“‹ Agentes disponÃ­veis:");
  agents.forEach((a, i) => {
    console.log(`   ${i + 1}. ${a.name} (${a.instructions?.length || 0} chars)`);
  });

  // Usar o primeiro agente com instruÃ§Ãµes grandes
  const agent = agents.find(a => (a.instructions?.length || 0) > 5000) || agents[0];

  if (!agent) {
    console.error("âŒ Nenhum agente com instruÃ§Ãµes longas encontrado!");
    process.exit(1);
  }

  console.log(`\nâœ… Usando agente: ${agent.name}`);
  console.log(`   InstruÃ§Ãµes: ${agent.instructions?.length || 0} caracteres`);
  console.log(`   Modelo: ${agent.gpt_model}`);

  if (!agent.gpt_api_key) {
    console.error("âŒ Agente nÃ£o tem chave API configurada!");
    process.exit(1);
  }

  // Construir prompts
  const systemPrompt = buildSystemPrompt(agent.name, agent.instructions || "");

  console.log(`\nğŸ“‹ System prompt total: ${systemPrompt.length.toLocaleString()} caracteres`);
  console.log(`ğŸ’¬ Mensagem do usuÃ¡rio: "${USER_MESSAGE}"\n`);

  console.log("â•".repeat(70));
  console.log("Testando cada configuraÃ§Ã£o (pode demorar 1-2 min)...\n");

  const results: TestResult[] = [];

  for (const config of CONFIGS) {
    process.stdout.write(`ğŸ§ª ${config.name}... `);
    const result = await testConfig(
      config,
      systemPrompt,
      USER_MESSAGE,
      agent.gpt_api_key
    );
    results.push(result);

    if (result.success) {
      console.log(
        `âœ… ${(result.time / 1000).toFixed(2)}s | ${result.tokens} tokens | ${result.responseLength} chars`
      );
    } else {
      console.log(`âŒ ${result.error}`);
    }

    // Esperar 1s entre testes para nÃ£o sobrecarregar
    await new Promise((r) => setTimeout(r, 1000));
  }

  // Ordenar por tempo
  const successResults = results.filter((r) => r.success);
  successResults.sort((a, b) => a.time - b.time);

  console.log("\n" + "â•".repeat(70));
  console.log("ğŸ“Š RANKING (mais rÃ¡pido primeiro):\n");

  successResults.forEach((r, i) => {
    const medal = i === 0 ? "ğŸ¥‡" : i === 1 ? "ğŸ¥ˆ" : i === 2 ? "ğŸ¥‰" : "  ";
    const timeStr = `${(r.time / 1000).toFixed(2)}s`.padEnd(8);
    const tokensStr = `${r.tokens} tokens`.padEnd(12);
    console.log(`${medal} ${timeStr} | ${tokensStr} | ${r.config}`);
  });

  console.log("\n" + "â•".repeat(70));

  if (successResults.length > 0) {
    const fastest = successResults[0];
    const current = results.find((r) => r.config.includes("ATUAL"));

    console.log("\nğŸ¯ RECOMENDAÃ‡ÃƒO:\n");

    if (current && current.success && fastest.config !== current.config) {
      const speedup = (
        ((current.time - fastest.time) / current.time) *
        100
      ).toFixed(0);
      console.log(`   ConfiguraÃ§Ã£o atual: ${(current.time / 1000).toFixed(2)}s`);
      console.log(
        `   ConfiguraÃ§Ã£o mais rÃ¡pida: ${(fastest.time / 1000).toFixed(2)}s`
      );
      console.log(`   Melhoria: ${speedup}% mais rÃ¡pido! âš¡\n`);
      console.log(`   ğŸ‘‰ Recomendo trocar para: ${fastest.config.split(" + ")[0]}`);
    } else if (current && fastest.config.includes("ATUAL")) {
      console.log("   âœ… A configuraÃ§Ã£o atual jÃ¡ Ã© a mais rÃ¡pida!");
    }
  }

  console.log(
    "\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  );
  console.log(
    "â•‘  TESTE COMPLETO                                                â•‘"
  );
  console.log(
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
  );
}

main().catch(console.error);
