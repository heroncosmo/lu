/**
 * TESTE LOCAL DA CONFIGURAÃ‡ÃƒO GPT-4.1-MINI
 * Simula exatamente o que o frontend faz no Assistente de Prompts
 */

// Simular prompt de 21k caracteres
function generate21kPrompt(): string {
  const basePrompt = `
VocÃª Ã© um Assistente de Atendimento profissional da LUCHOA IA, uma empresa inovadora de tecnologia.

## IDENTIDADE
- Nome: Assistente Virtual LUCHOA
- Empresa: LUCHOA IA - SoluÃ§Ãµes Inteligentes
- FunÃ§Ã£o: Atendimento ao cliente e suporte tÃ©cnico

## CONTEXTO DA EMPRESA
A LUCHOA IA Ã© uma empresa brasileira especializada em soluÃ§Ãµes de inteligÃªncia artificial.

## PRODUTOS
### PLANO STARTER - R$197/mÃªs
- 1.000 mensagens/mÃªs
- 1 nÃºmero de WhatsApp

### PLANO PROFESSIONAL - R$497/mÃªs  
- 5.000 mensagens/mÃªs
- 3 nÃºmeros de WhatsApp
- CRM integrado

### PLANO ENTERPRISE - R$997/mÃªs
- Mensagens ilimitadas
- NÃºmeros ilimitados
- IA personalizada

## FLUXO DE ATENDIMENTO
1. SaudaÃ§Ã£o inicial
2. IdentificaÃ§Ã£o da necessidade
3. QualificaÃ§Ã£o
4. Proposta de valor
5. Tratamento de objeÃ§Ãµes
6. Fechamento

## REGRAS DE COMUNICAÃ‡ÃƒO
- Sempre responder em portuguÃªs brasileiro
- Usar linguagem profissional mas acessÃ­vel
- Ser direto e objetivo
- Demonstrar empatia
`;

  let fullPrompt = basePrompt;
  while (fullPrompt.length < 21000) {
    fullPrompt += '\n' + basePrompt;
  }
  return fullPrompt.substring(0, 21000);
}

async function testGPT41Mini() {
  // Pedir API key do usuÃ¡rio
  const apiKey = process.env.OPENAI_API_KEY;
  
  if (!apiKey) {
    console.log('\nâŒ OPENAI_API_KEY nÃ£o definida.');
    console.log('   Para testar, execute: $env:OPENAI_API_KEY="sua-chave"; npx tsx scripts/test-local-speed.ts\n');
    
    // Mostrar o que DEVERIA acontecer
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    console.log('ğŸ“‹ RESUMO DAS CORREÃ‡Ã•ES FEITAS:');
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
    
    console.log('ANTES (ERRADO):');
    console.log('  - Modelo: gpt-4.1-mini');
    console.log('  - Role: "developer" âŒ');
    console.log('  - Token param: max_completion_tokens âŒ');
    console.log('  - Resultado: API tentava usar formato de reasoning model = LENTO\n');
    
    console.log('DEPOIS (CORRETO):');
    console.log('  - Modelo: gpt-4.1-mini');
    console.log('  - Role: "system" âœ…');  
    console.log('  - Token param: max_tokens âœ…');
    console.log('  - Resultado: API usa formato correto de non-reasoning = RÃPIDO\n');
    
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    console.log('ğŸ”§ ARQUIVOS CORRIGIDOS:');
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    console.log('1. src/components/AgentPromptImprover.tsx');
    console.log('   - Modelo fixo: gpt-4.1-mini');
    console.log('   - Role: system');
    console.log('   - max_tokens (nÃ£o max_completion_tokens)');
    console.log('');
    console.log('2. src/pages/AgentConfiguration.tsx');
    console.log('   - isReasoningModel = isGpt5Series || isOSeries');
    console.log('   - GPT-4.1 agora usa system role corretamente');
    console.log('   - max_tokens para non-reasoning models');
    console.log('');
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    console.log('ğŸ“Š EXPECTATIVA DE PERFORMANCE:');
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    console.log('');
    console.log('Com as correÃ§Ãµes:');
    console.log('  gpt-4.1-mini + system role + max_tokens');
    console.log('  â†’ Esperado: 5-15 segundos para 21k chars');
    console.log('');
    console.log('Antes das correÃ§Ãµes:');
    console.log('  gpt-4.1-mini + developer role + max_completion_tokens');
    console.log('  â†’ Resultado: 30-60+ segundos (API confusa com formato errado)');
    console.log('');
    return;
  }

  const prompt21k = generate21kPrompt();
  console.log(`\nğŸ“ Prompt gerado: ${prompt21k.length} caracteres`);
  
  const systemPrompt = `VocÃª Ã© um assistente especializado em editar playbooks de vendas.
VocÃª conversa naturalmente com o usuÃ¡rio E faz as ediÃ§Ãµes solicitadas no documento.`;

  const userMessage = `DOCUMENTO ATUAL DO PLAYBOOK:
\`\`\`
${prompt21k}
\`\`\`

MENSAGEM DO USUÃRIO:
Deixe o tom mais persuasivo e agressivo nas vendas.`;

  // CONFIGURAÃ‡ÃƒO CORRETA PARA GPT-4.1-MINI (non-reasoning model)
  const model = 'gpt-4.1-mini';
  const systemRole = 'system'; // NÃƒO developer!
  
  const promptChars = prompt21k.length;
  const estimatedDocTokens = Math.ceil(promptChars / 3);
  const maxTokens = Math.min(Math.max(estimatedDocTokens + 2000, 4000), 32000);
  
  console.log(`\nğŸš€ Testando ${model} com configuraÃ§Ã£o CORRETA:`);
  console.log(`   - Role: ${systemRole}`);
  console.log(`   - max_tokens: ${maxTokens}`);
  console.log(`   - Sem reasoning_effort (non-reasoning model)`);
  
  const startTime = Date.now();
  
  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify({
        model: model,
        messages: [
          { role: systemRole, content: systemPrompt },
          { role: 'user', content: userMessage }
        ],
        max_tokens: maxTokens,
        temperature: 0.3,
        response_format: {
          type: 'json_schema',
          json_schema: {
            name: 'ChatResponse',
            strict: true,
            schema: {
              type: 'object',
              properties: {
                resposta_chat: { type: 'string' },
                documento_atualizado: { type: 'string' },
                alteracao_feita: { type: 'boolean' }
              },
              required: ['resposta_chat', 'documento_atualizado', 'alteracao_feita'],
              additionalProperties: false
            }
          }
        }
      })
    });

    const elapsed = Date.now() - startTime;

    if (!response.ok) {
      const error = await response.json().catch(() => ({}));
      console.log(`\nâŒ ERRO: ${error.error?.message || response.status}`);
      return;
    }

    const data = await response.json();
    const content = data.choices[0]?.message?.content || '';
    
    console.log(`\nâœ… SUCESSO!`);
    console.log(`â±ï¸  Tempo total: ${(elapsed / 1000).toFixed(2)} segundos`);
    console.log(`ğŸ“Š Tokens usados:`, data.usage);
    console.log(`ğŸ“ Tamanho da resposta: ${content.length} caracteres`);
    
    // Parse JSON
    try {
      const parsed = JSON.parse(content);
      console.log(`\nğŸ’¬ Resposta do chat: "${parsed.resposta_chat.substring(0, 200)}..."`);
      console.log(`ğŸ“„ Documento atualizado: ${parsed.documento_atualizado.length} caracteres`);
      console.log(`âœï¸  AlteraÃ§Ã£o feita: ${parsed.alteracao_feita}`);
    } catch (e) {
      console.log(`\nâš ï¸  NÃ£o foi possÃ­vel parsear JSON, mas resposta recebida`);
    }

    if (elapsed < 15000) {
      console.log(`\nğŸ‰ EXCELENTE! Tempo abaixo de 15 segundos!`);
    } else if (elapsed < 30000) {
      console.log(`\nâœ… BOM! Tempo entre 15-30 segundos`);
    } else {
      console.log(`\nâš ï¸  LENTO! Tempo acima de 30 segundos`);
    }

  } catch (error: any) {
    console.log(`\nâŒ ERRO: ${error.message}`);
  }
}

testGPT41Mini();
