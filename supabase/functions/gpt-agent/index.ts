// @ts-ignore
import { serve } from "https://deno.land/std@0.177.0/http/server.ts";
// @ts-ignore
import { createClient } from "https://esm.sh/@supabase/supabase-js@2.39.7";

// Declara√ß√£o inline do namespace Deno para resolver erros de compila√ß√£o
declare const Deno: {
  env: {
    get(key: string): string | undefined;
  };
};

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
};

interface OpenAIMessage {
  role: "system" | "user" | "assistant";
  content: string;
}

// Fun√ß√£o para simular delay
const delay = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));

function getLastClientMessageId(messages: any[]): string | null {
  const lastClient = [...messages].reverse().find((m) => m.sender === "client");
  return lastClient?.id ?? null;
}

function buildFormattedHistory(messages: any[], image_url?: string): any[] {
  const out: any[] = [];

  for (let i = 0; i < messages.length; i++) {
    const msg = messages[i];
    const isLastMessage = i === messages.length - 1;
    const isUserMessage = msg.sender !== "agent";

    // Se √© a √∫ltima mensagem do usu√°rio e temos uma imagem, usar formato Vision
    if (isLastMessage && isUserMessage && image_url) {
      console.log("üì∏ Adicionando imagem √† √∫ltima mensagem do usu√°rio (Vision mode)");
      out.push({
        role: "user",
        content: [
          {
            type: "text",
            text: msg.message_content,
          },
          {
            type: "image_url",
            image_url: { url: image_url },
          },
        ],
      });
      continue;
    }

    // Mensagem normal (texto)
    out.push({
      role: isUserMessage ? "user" : "assistant",
      content: msg.message_content,
    });
  }

  return out;
}

serve(async (req) => {
  if (req.method === "OPTIONS") {
    return new Response("ok", { headers: corsHeaders });
  }

  try {
    console.log("=== INICIANDO FUN√á√ÉO GPT-AGENT ===");
    
    const requestBody = await req.json();
    const { session_id, image_url } = requestBody;
    console.log("Session ID recebido:", session_id);
    console.log("Imagem recebida:", image_url ? "Sim (Vision mode)" : "N√£o");
    
    if (!session_id) {
      throw new Error("session_id is required");
    }

    const supabaseAdmin = createClient(
      Deno.env.get("SUPABASE_URL")!,
      Deno.env.get("SUPABASE_SERVICE_ROLE_KEY")!
    );

    // Buscar dados completos da sess√£o com informa√ß√µes do cliente e configura√ß√µes de delay
    console.log("Buscando dados da sess√£o...");
    const { data: sessionData, error: sessionError } = await supabaseAdmin
      .from("prospecting_sessions")
      .select(`
        id,
        client_name,
        client_whatsapp_number,
        client_notes,
        status,
        agents (
          instructions,
          gpt_api_key,
          gpt_model,
          response_delay_seconds,
          word_delay_seconds
        )
      `)
      .eq("id", session_id)
      .single();

    if (sessionError || !sessionData) {
      console.error("Erro ao buscar sess√£o:", sessionError);
      throw new Error(`Sess√£o n√£o encontrada: ${sessionError?.message}`);
    }

    console.log("Dados da sess√£o:", JSON.stringify(sessionData, null, 2));

    const agent = sessionData.agents as any;
    if (!agent || !agent.instructions || !agent.gpt_api_key) {
      console.error("Configura√ß√£o do agente incompleta:", agent);
      throw new Error("A configura√ß√£o do agente est√° incompleta.");
    }

    // Usar o modelo configurado; fallback apenas se ausente
    const gptModel = agent.gpt_model ?? (() => {
      console.warn("Agente sem gpt_model definido, usando fallback gpt-4o");
      return "gpt-4o";
    })();
    const responseDelay = agent.response_delay_seconds || 30;
    const wordDelay = agent.word_delay_seconds || 1.6;
    
    console.log("=== CONFIGURA√á√ÉO DO AGENTE ===");
    console.log("Modelo GPT:", gptModel);
    console.log("Instru√ß√µes:", agent.instructions);
    console.log("Delay de resposta (leitura):", responseDelay, "segundos");
    console.log("Delay por palavra (digita√ß√£o):", wordDelay, "segundos");

    // Buscar hist√≥rico completo da conversa
    console.log("Buscando hist√≥rico de mensagens...");
    const { data: initialMessages, error: messagesError } = await supabaseAdmin
      .from("whatsapp_messages")
      .select("id, sender, message_content, timestamp")
      .eq("session_id", session_id)
      .order("timestamp", { ascending: true });

    if (messagesError) {
      console.error("Erro ao buscar mensagens:", messagesError);
      throw new Error(`Falha ao buscar mensagens: ${messagesError.message}`);
    }

    let messages = initialMessages || [];

    console.log("=== HIST√ìRICO DE MENSAGENS ===");
    console.log("N√∫mero de mensagens:", messages.length);
    console.log("Mensagens:", JSON.stringify(messages, null, 2));

    // === BUSCAR ANOTA√á√ïES DO CLIENTE PARA CONTEXTO DA IA ===
    // Primeiro verificar anota√ß√µes salvas diretamente na sess√£o (do formul√°rio)
    let clientAnnotationsContext = "";
    
    if (sessionData.client_notes && sessionData.client_notes.trim()) {
      console.log("=== ANOTA√á√ïES DO FORMUL√ÅRIO ENCONTRADAS ===");
      console.log("Anota√ß√µes:", sessionData.client_notes);
      clientAnnotationsContext = `

üìù ANOTA√á√ïES DO CLIENTE (informa√ß√µes do vendedor):
${sessionData.client_notes}

USE ESTAS INFORMA√á√ïES PARA PERSONALIZAR TODAS AS RESPOSTAS!`;
    }
    
    // Depois buscar o crm_contact para obter o crm_client_code
    const { data: crmContact } = await supabaseAdmin
      .from("crm_contacts")
      .select("id, crm_client_code, notes, segment, kanban_status")
      .eq("name", sessionData.client_name)
      .single();

    if (crmContact?.crm_client_code) {
      // Buscar anota√ß√µes da IA sobre este cliente
      const { data: annotations } = await supabaseAdmin
        .from("client_annotations")
        .select("annotation_type, content, importance, created_at")
        .eq("crm_client_code", crmContact.crm_client_code)
        .eq("is_active", true)
        .order("importance", { ascending: false })
        .limit(10);

      if (annotations && annotations.length > 0) {
        console.log("=== ANOTA√á√ïES DO CLIENTE ENCONTRADAS ===");
        console.log("N√∫mero de anota√ß√µes:", annotations.length);
        
        clientAnnotationsContext = `

ANOTA√á√ïES IMPORTANTES SOBRE O CLIENTE:
${annotations.map(a => `- [${a.annotation_type.toUpperCase()}] ${a.content}`).join('\n')}

USE ESTAS INFORMA√á√ïES PARA PERSONALIZAR A CONVERSA. Por exemplo:
- Se o cliente √© "calmo", use tom mais sereno
- Se h√° prefer√™ncias de hor√°rio, respeite
- Se h√° contexto sobre sa√∫de/fam√≠lia, demonstre empatia
- Se h√° hist√≥rico de negocia√ß√£o, lembre-se das condi√ß√µes`;
      }

      // Incluir notas gerais do CRM se existirem
      if (crmContact.notes) {
        clientAnnotationsContext += `

NOTAS DO CRM SOBRE O CLIENTE:
${crmContact.notes}`;
      }
    }

    // Construir o contexto da conversa com as instru√ß√µes do agente
    const systemPrompt = `Voc√™ √© um agente de prospec√ß√£o de vendas com as seguintes caracter√≠sticas e instru√ß√µes:

${agent.instructions}

CONTEXTO ATUAL:
- Cliente: ${sessionData.client_name}
- WhatsApp: ${sessionData.client_whatsapp_number}
- Status da conversa: ${sessionData.status}
${clientAnnotationsContext}

CAPACIDADES ESPECIAIS (MUITO IMPORTANTE - LEIA COM ATEN√á√ÉO):
- Voc√™ PODE ver e analisar imagens que o cliente enviar. Se receber uma imagem, descreva o que voc√™ v√™ e responda de forma relevante.
- Voc√™ PODE receber √°udios! Os √°udios do cliente s√£o AUTOMATICAMENTE TRANSCRITOS para texto antes de chegar a voc√™. Quando o cliente envia um √°udio, voc√™ recebe o texto da transcri√ß√£o. NUNCA diga que n√£o consegue ouvir √°udios - voc√™ j√° est√° recebendo o conte√∫do transcrito!
- Se a mensagem do cliente parece uma fala natural (como "Beleza, mas voc√™ t√° me ouvindo?"), √© porque foi um √°udio transcrito. Responda normalmente ao conte√∫do.

REGRAS IMPORTANTES PARA RESPOSTAS:
1. Seja sempre amig√°vel, profissional e persuasivo
2. Personalize todas as mensagens para o cliente ${sessionData.client_name}
3. Seja breve e direto ao ponto
4. Mantenha o tom de conversa, n√£o de discurso
5. Responda diretamente ao que o cliente disse
6. N√£o repita informa√ß√µes j√° mencionadas
7. Use linguagem coloquial e natural
8. SIGA EXATAMENTE AS INSTRU√á√ïES DO AGENTE ACIMA
9. Se o cliente enviar uma imagem, analise-a e responda de forma relevante ao conte√∫do da imagem
10. NUNCA diga "n√£o consigo ouvir √°udios" ou "me manda por escrito" - voc√™ J√Å recebe os √°udios transcritos!

CONTINUIDADE DA CONVERSA (CR√çTICO):
- Voc√™ est√° no MEIO de uma conversa, N√ÉO no in√≠cio. O hist√≥rico acima mostra tudo que j√° foi dito.
- NUNCA reinicie a prospec√ß√£o ou cumprimente como se fosse a primeira mensagem.
- Se o cliente diz "blz", "ok", "beleza", "t√° bom", "pode ser", continue a conversa naturalmente, n√£o recomece.
- Respostas curtas do cliente (1-2 palavras) s√£o confirma√ß√µes, n√£o pedidos para recome√ßar.
- Mantenha o fluxo da conversa - leia o hist√≥rico para entender onde voc√™s pararam.
- Se j√° houve troca de mensagens, voc√™ j√° se apresentou. N√ÉO se apresente novamente.

FORMATO DAS RESPOSTAS:
- Escreva TUDO EM UM √öNICO PAR√ÅGRAFO
- N√ÉO USE QUEBRAS DE LINHA
- Use apenas espa√ßos simples entre as frases
- Pare√ßa uma mensagem de WhatsApp real e natural
- M√°ximo 2-3 frases por resposta para n√£o ficar muito longo

IMPORTANTE: Sua personalidade e forma de falar devem seguir EXATAMENTE as instru√ß√µes do agente fornecidas acima.

=== DETEC√á√ÉO AUTOM√ÅTICA DE AGENDAMENTOS (MUITO IMPORTANTE) ===
ANALISE TODO O HIST√ìRICO DA CONVERSA para detectar se o cliente PEDIU para ser contatado em um momento futuro.
Exemplos de pedidos:
- "fala comigo daqui 2 horas" ‚Üí agendar 2 horas
- "me chama amanh√£" ‚Üí agendar 1 dia
- "pode ligar daqui 30 minutos" ‚Üí agendar 30 minutos
- "volta a falar comigo em 5 minutos" ‚Üí agendar 5 minutos
- "chama eu daqui 4 minutos" ‚Üí agendar 4 minutos
- "agora n√£o d√°, me liga depois" ‚Üí agendar 1 hora (default)
- "t√¥ ocupado, volta depois" ‚Üí agendar 1 hora (default)

QUANDO DETECTAR UM PEDIDO DE AGENDAMENTO, FA√áA AS DUAS COISAS:
1. NA SUA RESPOSTA: Mencione que voc√™ vai retornar conforme o cliente pediu! Exemplo: "Beleza, te chamo daqui a 4 minutos ent√£o!" ou "T√° certo, volto a falar contigo em 5 minutinhos!"
2. NO FINAL: Adicione a tag [AGENDAR:X:UNIDADE:MOTIVO]

Onde:
- X = n√∫mero (ex: 2, 30, 5)
- UNIDADE = minutes, hours ou days
- MOTIVO = breve descri√ß√£o

Exemplos de formato:
[AGENDAR:5:minutes:Cliente pediu para falar daqui 5 minutos]
[AGENDAR:2:hours:Cliente est√° ocupado]
[AGENDAR:1:days:Retomar conversa amanh√£]

Se N√ÉO houver pedido de agendamento, N√ÉO inclua nada extra.
O sistema vai remover essa tag antes de enviar ao cliente.

Exemplo de formato correto:
Que bom ouvir isso, Rodrigo! Tudo tranquilo por aqui tamb√©m, gra√ßas a Deus. Como est√£o as coisas por a√≠? Muita porreria ou t√° de boa?`;

    // === CONFIGURA√á√ÉO DE MODELOS OPENAI (Junho 2025) ===
    // Baseado na documenta√ß√£o oficial: https://platform.openai.com/docs/guides/latest-model
    // 
    // GPT-5 Series (gpt-5.1, gpt-5, gpt-5-mini, gpt-5-nano, gpt-5-pro):
    //   - Usa role "developer" (n√£o "system")
    //   - Usa max_completion_tokens (n√£o max_tokens)
    //   - TODOS requerem reasoning_effort obrigat√≥rio
    //   - gpt-5.1: suporta "none", "low", "medium", "high" (default: none)
    //   - gpt-5, gpt-5-mini, gpt-5-nano: suporta "low", "medium", "high" (N√ÉO suporta "none"!)
    //   - gpt-5-pro: suporta "medium", "high" (default: high, mais inteligente)
    //   - N√ÉO suporta temperature (exceto gpt-5.1 com reasoning=none)
    //
    // GPT-4.1 Series (gpt-4.1, gpt-4.1-mini, gpt-4.1-nano):
    //   - Usa role "developer" 
    //   - Usa max_completion_tokens
    //   - N√ÉO usa reasoning_effort (n√£o √© modelo de racioc√≠nio)
    //   - Suporta temperature
    //
    // O-series (o3, o3-mini, o4-mini):
    //   - Usa role "developer"
    //   - Usa max_completion_tokens + reasoning_effort
    //
    // Modelos legados (gpt-4o, gpt-4-turbo, etc):
    //   - Usa role "system"
    //   - Usa max_tokens + temperature
    
    const isGpt5Series = gptModel.startsWith('gpt-5');
    const isGpt51 = gptModel.startsWith('gpt-5.1');
    const isGpt5Pro = gptModel === 'gpt-5-pro';
    const isGpt41Series = gptModel.startsWith('gpt-4.1');
    const isOSeries = gptModel.startsWith('o3') || gptModel.startsWith('o4');
    const isNewModel = isGpt5Series || isGpt41Series || isOSeries;
    
    // Role: developer para modelos novos, system para legados
    const systemRole = isNewModel ? "developer" : "system";

    let lastClientMessageId = getLastClientMessageId(messages);

    // Construir o hist√≥rico da conversa para o GPT
    let formattedMessages: any[] = [
      { role: systemRole, content: systemPrompt },
      ...buildFormattedHistory(messages, image_url),
    ];

    console.log("=== MENSAGENS FORMATADAS PARA O GPT ===");
    console.log("N√∫mero de mensagens formatadas:", formattedMessages.length);
    console.log("Modo Vision:", image_url ? "Ativado" : "Desativado");
    console.log("√öltima mensagem do usu√°rio:", typeof formattedMessages[formattedMessages.length - 1]?.content === 'string' 
      ? formattedMessages[formattedMessages.length - 1]?.content 
      : "[Mensagem com imagem]");

    // === SIMULA√á√ÉO DE TEMPO DE LEITURA ===
    // NOTA: N√ÉO verificamos mais novas mensagens aqui porque:
    // 1. O batching em receive-whatsapp-message j√° aguarda TODAS as mensagens estabilizarem
    // 2. Quando gpt-agent √© chamado, j√° temos todas as mensagens do lote
    // 3. Se nova mensagem chegar depois, ser√° um NOVO lote processado separadamente
    // 4. Verificar aqui causava loop infinito de cancelamentos sem resposta
    console.log(`=== SIMULANDO TEMPO DE LEITURA (${responseDelay}s) ===`);
    await delay(responseDelay * 1000);
    console.log(`‚úÖ Delay de leitura conclu√≠do`);

    // Rebuscar hist√≥rico ap√≥s o delay para evitar responder sem as √∫ltimas mensagens
    // que podem chegar durante o "tempo de leitura".
    console.log("=== REBUSCANDO HIST√ìRICO AP√ìS DELAY ===");
    const { data: messagesAfterDelay, error: messagesAfterDelayError } = await supabaseAdmin
      .from("whatsapp_messages")
      .select("id, sender, message_content, timestamp")
      .eq("session_id", session_id)
      .order("timestamp", { ascending: true });

    if (messagesAfterDelayError) {
      console.warn("‚ö†Ô∏è Falha ao rebuscar mensagens ap√≥s delay (seguindo com hist√≥rico inicial):", messagesAfterDelayError);
    } else if (messagesAfterDelay) {
      const lastClientAfterDelay = getLastClientMessageId(messagesAfterDelay);
      const changed = messagesAfterDelay.length !== messages.length || lastClientAfterDelay !== lastClientMessageId;

      if (changed) {
        console.log("üîÑ Hist√≥rico atualizado ap√≥s delay. Reformatando mensagens...");
        console.log("Mensagens antes:", messages.length, "| depois:", messagesAfterDelay.length);
        console.log("√öltima msg client antes:", lastClientMessageId, "| depois:", lastClientAfterDelay);

        messages = messagesAfterDelay;
        lastClientMessageId = lastClientAfterDelay;
        formattedMessages = [
          { role: systemRole, content: systemPrompt },
          ...buildFormattedHistory(messages, image_url),
        ];
      } else {
        console.log("‚úÖ Nenhuma mudan√ßa no hist√≥rico ap√≥s delay");
      }
    }

    console.log("=== CHAMANDO API DA OPENAI ===");
    
    // Par√¢metros de tokens
    const tokenParam = isNewModel ? { max_completion_tokens: 1000 } : { max_tokens: 1000 };
    
    // Par√¢metros extras (reasoning_effort / temperature)
    let extraParams: Record<string, any> = {};
    
    if (isGpt5Series) {
      // Todos os modelos GPT-5 requerem reasoning_effort
      if (isGpt5Pro) {
        // gpt-5-pro: default √© high, √© o mais inteligente
        extraParams = { reasoning_effort: "medium" };
      } else if (isGpt51) {
        // gpt-5.1: suporta "none" para resposta r√°pida
        extraParams = { reasoning_effort: "none" };
      } else {
        // gpt-5, gpt-5-mini, gpt-5-nano: m√≠nimo √© "low", N√ÉO suporta "none"
        extraParams = { reasoning_effort: "low" };
      }
    } else if (isOSeries) {
      // O-series tamb√©m precisa de reasoning_effort
      extraParams = { reasoning_effort: "low" };
    } else if (isGpt41Series) {
      // GPT-4.1 n√£o √© modelo de racioc√≠nio, suporta temperature
      extraParams = { temperature: 0.8 };
    } else if (!isNewModel) {
      // Modelos legados (gpt-4o, gpt-4-turbo, etc)
      extraParams = { temperature: 0.8 };
    }
    
    console.log(`üß† Modelo: ${gptModel} | isNewModel: ${isNewModel} | systemRole: ${systemRole} | extraParams:`, JSON.stringify(extraParams));
    
    // Chamada prim√°ria
    let openaiResponse = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${agent.gpt_api_key}`,
      },
      body: JSON.stringify({
        model: gptModel,
        messages: formattedMessages,
        ...tokenParam,
        ...extraParams,
      }),
    });

    // SEM FALLBACK - vamos mostrar o erro real da API
    if (!openaiResponse.ok) {
      let errorBody: any = null;
      try { errorBody = await openaiResponse.json(); } catch { errorBody = await openaiResponse.text(); }
      console.error("‚ùå Erro na API da OpenAI:", typeof errorBody === 'string' ? errorBody : JSON.stringify(errorBody, null, 2));
      console.error("‚ùå Status:", openaiResponse.status);
      console.error("‚ùå Modelo usado:", gptModel);
      console.error("‚ùå isNewModel:", isNewModel);
      const errorMessage = (errorBody as any)?.error?.message || JSON.stringify(errorBody);
      throw new Error(`Erro na API da OpenAI (${openaiResponse.status}): ${errorMessage}`);
    }

    const responseJson = await openaiResponse.json();
    let gptMessage = responseJson.choices[0].message.content.trim();
    
    console.log("=== RESPOSTA BRUTA DO GPT ===");
    console.log("Resposta completa:", JSON.stringify(gptMessage));
    
    // REMOVER ASPAS DUPLAS DO IN√çCIO E FIM SE EXISTIREM
    // Verificar se a mensagem come√ßa e termina com aspas duplas
    if (gptMessage.startsWith('"') && gptMessage.endsWith('"')) {
      console.log("Removendo aspas duplas do in√≠cio e fim da mensagem");
      gptMessage = gptMessage.slice(1, -1);
    }
    
    console.log("=== MENSAGEM AP√ìS REMO√á√ÉO DE ASPAS ===");
    console.log(gptMessage);

    // === FORMATA√á√ÉO HUMANA DA MENSAGEM (CORRIGIDA PARA UM √öNICO PAR√ÅGRAFO) ===
    // Remover todas as quebras de linha e substituir por espa√ßos simples
    gptMessage = gptMessage
      .replace(/\n+/g, ' ') // Substituir todas as quebras de linha por espa√ßos
      .replace(/\s+/g, ' ') // Substituir m√∫ltiplos espa√ßos por um √∫nico espa√ßo
      .replace(/^\s+|\s+$/g, '') // Trim
      .replace(/\.\s+/g, '. ') // Garantir espa√ßo ap√≥s pontos
      .replace(/\?\s+/g, '? ') // Garantir espa√ßo ap√≥s pontos de interroga√ß√£o
      .replace(/\!\s+/g, '! '); // Garantir espa√ßo ap√≥s pontos de exclama√ß√£o

    // === DETECTAR E PROCESSAR AGENDAMENTO NA RESPOSTA ===
    // Formato: [AGENDAR:X:UNIDADE:MOTIVO]
    const scheduleRegex = /\[AGENDAR:(\d+):(\w+):([^\]]+)\]/i;
    const scheduleMatch = gptMessage.match(scheduleRegex);
    
    if (scheduleMatch) {
      console.log("=== AGENDAMENTO DETECTADO NA RESPOSTA DA IA ===");
      const timeValue = parseInt(scheduleMatch[1]);
      const timeUnit = scheduleMatch[2].toLowerCase();
      const reason = scheduleMatch[3];
      
      console.log(`Tempo: ${timeValue} ${timeUnit}`);
      console.log(`Motivo: ${reason}`);
      
      // Remover a tag da mensagem antes de enviar ao cliente
      gptMessage = gptMessage.replace(scheduleRegex, '').trim();
      
      // Calcular a data/hora do agendamento
      const now = new Date();
      let scheduledFor = new Date(now);
      
      switch (timeUnit) {
        case 'minutes':
          scheduledFor.setMinutes(scheduledFor.getMinutes() + timeValue);
          break;
        case 'hours':
          scheduledFor.setHours(scheduledFor.getHours() + timeValue);
          break;
        case 'days':
          scheduledFor.setDate(scheduledFor.getDate() + timeValue);
          break;
        default:
          scheduledFor.setHours(scheduledFor.getHours() + 1); // Default 1 hora
      }
      
      console.log(`üìÖ Agendando contato para: ${scheduledFor.toISOString()}`);
      
      // Criar resumo do contexto da conversa (√∫ltimas 5 mensagens)
      const conversationContext = messages.slice(-5).map((m: any) => 
        `${m.sender === 'agent' ? 'Voc√™' : sessionData.client_name}: ${m.message_content}`
      ).join('\n');
      
      // Salvar o agendamento no banco
      try {
        const { error: scheduleError } = await supabaseAdmin
          .from('scheduled_contacts')
          .insert({
            session_id: session_id,
            client_name: sessionData.client_name,
            client_whatsapp_number: sessionData.client_whatsapp_number,
            scheduled_for: scheduledFor.toISOString(),
            reason: reason,
            context: `${reason}

CONTEXTO DA CONVERSA ANTERIOR:
${conversationContext}`,
          });
        
        if (scheduleError) {
          console.error("‚ùå Erro ao salvar agendamento:", scheduleError);
        } else {
          console.log("‚úÖ Agendamento salvo com sucesso!");
        }
      } catch (err) {
        console.error("‚ùå Exce√ß√£o ao salvar agendamento:", err);
      }
    }

    console.log("=== MENSAGEM FORMATADA (√öNICO PAR√ÅGRAFO) ===");
    console.log("Mensagem final:", gptMessage);

    // === C√ÅLCULO DETALHADO DO TEMPO ===
    const wordCount = gptMessage.split(/\s+/).length;
    const typingDelay = wordCount * wordDelay * 1000;
    const totalDelay = responseDelay + (wordCount * wordDelay);
    
    console.log("=== C√ÅLCULO DE TEMPO DETALHADO ===");
    console.log("Mensagem final:", `"${gptMessage}"`);
    console.log("N√∫mero de palavras:", wordCount);
    console.log("Delay de resposta (leitura):", responseDelay, "segundos");
    console.log("Delay por palavra (digita√ß√£o):", wordDelay, "segundos");
    console.log("Tempo de digita√ß√£o:", wordCount * wordDelay, "segundos");
    console.log("Tempo total:", totalDelay, "segundos");
    console.log("Tempo total em ms:", totalDelay * 1000, "ms");

    // Simular tempo de digita√ß√£o (delay por palavra)
    console.log(`=== SIMULANDO TEMPO DE DIGITA√á√ÉO ===`);
    console.log(`Simulando digita√ß√£o de ${wordCount} palavras (${typingDelay}ms)...`);
    await delay(typingDelay);

    // === EXTRA√á√ÉO AUTOM√ÅTICA DE ANOTA√á√ïES ===
    // Analisar a conversa para extrair insights sobre o cliente
    if (crmContact?.crm_client_code && messages && messages.length > 0) {
      try {
        console.log("=== ANALISANDO CONVERSA PARA EXTRAIR INSIGHTS ===");
        
        // Montar hist√≥rico para an√°lise
        const conversationHistory = messages.map((m: any) => 
          `${m.sender === 'agent' ? 'Agente' : 'Cliente'}: ${m.message_content}`
        ).join('\n');
        
        const analysisPrompt = `Analise esta conversa de vendas e extraia APENAS insights RELEVANTES e NOVOS sobre o cliente.
Retorne um JSON com array "insights" contendo objetos com:
- "type": um de ["mood", "availability", "preference", "relationship", "context", "health", "business"]
- "content": texto descritivo breve (m√°ximo 100 caracteres)
- "importance": n√∫mero de 1 a 10 (10 = muito importante)

REGRAS:
1. Extraia APENAS informa√ß√µes que o CLIENTE revelou (n√£o o agente)
2. Ignore sauda√ß√µes comuns e respostas gen√©ricas
3. Foque em: humor, disponibilidade, prefer√™ncias, problemas de sa√∫de, situa√ß√£o familiar, interesse de neg√≥cio
4. Se n√£o houver insights relevantes, retorne {"insights": []}
5. M√°ximo 3 insights por an√°lise

CONVERSA:
${conversationHistory}

√öLTIMA MENSAGEM DO CLIENTE: ${messages[messages.length - 1]?.message_content || 'N/A'}

Retorne APENAS o JSON, sem explica√ß√µes.`;

        const analysisResponse = await fetch("https://api.openai.com/v1/chat/completions", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${agent.gpt_api_key}`,
          },
          body: JSON.stringify({
            model: "gpt-3.5-turbo", // Usar modelo mais barato para an√°lise
            messages: [{ role: "user", content: analysisPrompt }],
            max_tokens: 300,
            temperature: 0.3,
          }),
        });

        if (analysisResponse.ok) {
          const analysisJson = await analysisResponse.json();
          let analysisText = analysisJson.choices[0].message.content.trim();
          
          // Limpar markdown se existir
          analysisText = analysisText.replace(/```json\n?/g, '').replace(/```\n?/g, '');
          
          try {
            const insights = JSON.parse(analysisText);
            console.log("Insights extra√≠dos:", JSON.stringify(insights, null, 2));
            
            if (insights.insights && insights.insights.length > 0) {
              for (const insight of insights.insights) {
                // Salvar cada insight como anota√ß√£o
                const { error: annotationError } = await supabaseAdmin.rpc('add_ai_annotation', {
                  p_crm_client_code: crmContact.crm_client_code,
                  p_annotation_type: insight.type,
                  p_title: insight.type.toUpperCase(),
                  p_content: insight.content,
                  p_relevance: insight.importance,
                  p_is_temporary: false,
                  p_expires_at: null,
                  p_source_message_id: null
                });
                
                if (annotationError) {
                  console.error("Erro ao salvar anota√ß√£o:", annotationError);
                } else {
                  console.log(`‚úÖ Anota√ß√£o salva: [${insight.type}] ${insight.content}`);
                }
              }
            }
          } catch (parseError) {
            console.log("N√£o foi poss√≠vel parsear insights (OK se n√£o houver):", analysisText);
          }
        }
      } catch (analysisError) {
        // N√£o falhar a resposta principal por causa da an√°lise
        console.log("Erro na an√°lise de insights (n√£o cr√≠tico):", analysisError);
      }
    }

    console.log("=== RETORNANDO RESPOSTA FINAL ===");
    const responseData = {
      reply: gptMessage, 
      gptModel,
      context: {
        messageCount: messages.length,
        lastClientMessageId,
      },
      delays: {
        responseDelay,
        wordDelay,
        wordCount,
        totalDelay: totalDelay
      }
    };
    
    console.log("Dados de retorno:", JSON.stringify(responseData, null, 2));

    return new Response(JSON.stringify(responseData), {
      headers: { ...corsHeaders, "Content-Type": "application/json" },
      status: 200,
    });

  } catch (error) {
    console.error("=== ERRO N√ÉO TRATADO ===:", error);
    return new Response(JSON.stringify({ error: error.message }), {
      headers: { ...corsHeaders, "Content-Type": "application/json" },
      status: 500,
    });
  }
});